
1. Install python 3.7.4 from python.org

pip install pandas

pip install xlrd

pip install configparser
pip install mysql
pip install mysql-connector-python

1.2 list of modules

python > modules list
       > help(configparser)


2. python -m pip install --upgrade pip


D:\Google Drive\my_personal_pack\invest\Equity\icici-bank-txn-data\fy1617>

d:\> python "D:\Google Drive\my_github\GitHub\gotolong\src\dividend\excel_to_csv.py" OpTransactionHistory-fy1617.xls OpTransactionHistory-fy1617.csv 0

D:\Google Drive\my_personal_pack\invest\Equity\icici-bank-txn-data\fy1617>python -m pdb  "D:\Google Drive\my_github\GitHub\gotolong\src\dividend\excel_to_csv.py" OpTransactionHistory-fy1617.xls OpTransactionHistory-fy1617.csv 1


3.  Python with debugger

python -m pdb x.py

4. To introduce single quote and double quote. This is required in GIT BASH for 'Google Drive' as that is in path.

use r with """" (triple quotes) and can embed either single quote or double quote.

use r""" """

4. python : expand file names using * etc in the path.

import glob
glob.glob(path)

5. windows port
   5.1 use python x.py instead of /usr/bin/python in .py file.
   5.2 handle Google Drive with a space by renaming it to GoogleDrive otherwise GitBash and .py modules will continue to get confused.

6. Migration to 3.7 from 2.*
   6.1 The print has been converted to a function so print must be enclosed in () like print('hello')


7. dataframe tips

7.0 read csv file as dataframe

# Load the Pandas libraries with alias 'pd'
import pandas as pd

# Read data from file 'filename.csv'
# (in the same directory that your python process is based)
# Control delimiters, rows, column names with read_csv (see later)
data = pd.read_csv("filename.csv")

# Preview the first 5 lines of the loaded data
data.head()

   7.1> exclude columns with NaN

# Keep only if Transaction Remarks column is not NA
df = df[df['Unnamed: 5'].notnull()]

7.2> exclude columns with special content
# first line is 'Transaction Date from' : case sensitive
df = df[df['Unnamed: 1'] != 'Transaction Date from']

7.3> drop first column (column with an index)
# remove first column (NaN before S.No) - axis 1 is column, 0 is row
df.drop(df.columns[0], axis=1, inplace=True)

7.4> drop last column
# remove last column : Balance (INR)
df = df.iloc[:, :-1]

7.5> set columns
# change columns from second line from top
df.columns = df.iloc[0]

7.6> drop by column names (column index).

# axis = 1 means column name
df.drop(df.columns[[0, 4, 2]], axis = 1, inplace = True)


8. arguments using argument specifier : argparse module

import argparse

parser = argparse.ArgumentParser(description='Process arguments')
# dest= not required as option itself is the destination in args
parser.add_argument('--out_type', default='out_plain', help='out_plain | out_csv')
parser.add_argument('--sort_type', default='sort_frequency', help='sort_frequency')
parser.add_argument('--summary_type', default='summary_yes|summary_no', help='summary_yes')
parser.add_argument('--debug_level', default='0', help='debug level 0|1|2|3', type=int, choices=[0, 1, 2, 3])
parser.add_argument('--dividend_file', nargs='+', dest='dividend_file', help='dividend file')
parser.add_argument('--bonus_file', nargs='+', dest='bonus_file', help='bonus file')

args = parser.parse_args()
# print(args)

program_name = sys.argv[0]

out_type= args.out_type
sort_type= args.sort_type
summary_type= args.summary_type
debug_level= args.debug_level
# use the argument as pattern
bonus_filenames = glob.glob(args.bonus_file[0])
dividend_filenames = glob.glob(args.dividend_file[0])

9. reindent (replace tabs with 4 whitespaces)
-r recursively
directory - for all files in that directory

python $(dirname `which python`)/Tools/scripts/reindent.py -r .

10. 2-d python array

XYZ_2d[row, column] = 1

11. duplicate the dictionary in case you are going to browse it and also manipulate it using del and pop.
    x_dup = dict(y)


12. fh.write() takes only 1 argument

13. Sorting the data using keys/values in associative array. An argument reverse=True can be given to change the order.
    For sorting using values - use key=associative_array.__getitem__

        if filter_rows:
            sorted_input = sorted(self.sc_nsecode_industry, key=self.sc_nsecode_industry.__getitem__)
        else:
            sorted_input = sorted(self.sc_nsecode)

14. variable type
    list - x_list = ['1', '2', '3'] - read write list
    tuple - x_tuple = ('1', '2', '3') - read only list (cannot be edited, pushed, popped etc)
    dict - x_dict = { 'x' : '1' : 'y' : 2} - key value list (associative array)

14.2 list functions
     list.append(x)
     list.pop() -> pop an element
15. dictionary from two lists
    # create a dictionary out of two lists
    dict(zip(keys,values))

16. fix the stripping of all columns in a row (list)
    # fix the stripping : redundant spaces etc
    row = [column.strip() for column in row]

17. count of elements in list and dictionary
    count_elements = len (kv_dict.keys())

18. dataframe - round the column value of float
    df[["avg_mcap"]] = df[["avg_mcap"]].astype(int)

19. string functions
    x.find('abc') - find substring in the string, return index.

20. print usage
    20.1 to avoid automatic newline with print use, end=
            print('x', end='')

21. string replace :
            string.replace(old, new, count)

22. for mysql and mariadb

pip install mysql
pip install mysql-connector-python


23. pip freeze (get the list of packages already installed)
 23.1 pip freeze > requirements.txt
 23.2

24. uninstall packages
  24.1 pip uninstall gunicorn

25. Generate wheel package
  25.1 pip install wheel
  25.2 python setup.py bdist_wheel

26. year, month, day, timestamp
   26.1 current_date = date.today()
   26.2 current_year = current_date.year

  27.
    txn_month_abre = current_date.strftime('%b')


28. Django debug

import pdb; pdb.set_trace()
or

breakpoint()  #from Python3.7

29. get rid of newline etc at end : chomp equivalent on python.

str.rstrip()

30. dataframe from model

        df_bstmtdiv = pd.DataFrame.from_records(BstmtDiv.objects.all().values())
        df_amfi = pd.DataFrame.from_records(Amfi.objects.all().values())

31. Record Linking and Fuzzy Matching

https://pbpython.com/record-linking.html

32. check data type of table : Is that text? Should be Int or Float.

function sum(text) does not exist
LINE 1: SELECT SUM("user_demat_sum"."ds_mktvalue") AS "mktvalue" FRO...
               ^
HINT:  No function matches the given name and argument types. You might need to add explicit type casts.